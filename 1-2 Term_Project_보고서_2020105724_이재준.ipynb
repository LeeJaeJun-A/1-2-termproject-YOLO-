{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV을 이용한 신발 인식프로그램"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 목표 및 이 프로젝트의 필요성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "패션 관련 유튜브를 볼 때 흔히 \"이 옷 어디 거에요?\"하고 정보를 물어보는 댓글들을 흔히 볼 수 있습니다.<br>\n",
    "![youtube](report_photos/youtube.png)<br>\n",
    "![youtubecomment](report_photos/comments.png)<br>\n",
    "(2020.10.14일 기준 13시간이 지난 영상에 130여 개 정도의 댓글에서 종종 찾아볼 수 있었습니다.)<br>\n",
    "유튜버 입장에서는 댓글이 영상마다 많이 달리기 때문에 일일이 답변을 하기 힘들 것이고, 댓글을 쓴 시청자 입장에서는 원하는 대답을 얻기 어려울 것입니다.<br>\n",
    "그렇기 때문에 이미지를 분석해서 그 제품이 무엇인지 알려준다면 이러한 문제를 적절하게 해결할 수 있다고 생각을 하였습니다.<br>\n",
    "다양한 품목들 중 먼저 신발을 대상으로 선정하여 적절하게 구별해낼 수 있도록 구현하여 다른 품목들도 확장해나갈 수 있는 발판을 세우는 것이 이번 프로젝트의 목표입니다.<br>\n",
    "초기 계획에서는 상품을 찾고 그 상품에 대한 url을 연결해주는 쪽으로 구상하였습니다.<br>\n",
    "하지만 이용자마다 선호하는 쇼핑몰이 다를 수 있고, 많은 쇼핑몰에 같은 상품이 존재하기 때문에  그 상품에 대한 적절한 사이트를 추천하는 것은비효율적이라고 판단하였습니다.<br>\n",
    "따라서 url 연결을 하는 부분을 제외하고 사진을 보다 편리하게 선택하면서 상품을 찾을 수 있는 것에 집중하여 GUI로 프로그램을 구성하기로 결정하였습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로토타입"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PROTOTYPE](report_photos/prototype.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 획득(크롤링)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무신사 스토어 2020.10.18일 기준 스니커즈 부분 주간 랭킹 1,2,3 위인 척 70 클래식 블랙 162058Cb, BW 독일군 스니커즈 화이트 BZ0579, 에어 조던1 하이 OG 디올 리미티드 에디션으로 프로젝트를 진행하였습니다.<br>\n",
    "![ranking](report_photos/10.18_ranking.png)\n",
    "\n",
    "-결과<br>\n",
    "<img src=\"report_photos/crawling_result1.png\" align=\"left\">\n",
    "![crawling_reulst](report_photos/crawling_result2.png)\n",
    "<br><br>\n",
    "결과 내에서 적절하지 못한 사진은 수작업으로 제외하였습니다.(신발 안쪽, 바닥 사진, 신발 박스 사진, 같은 브랜드 다른 신발 등)<br><br>\n",
    "\n",
    "소스코드: photographic_crawing.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# from urllib.parse import quote_plus\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "#name\n",
    "Air_jordan = 'Air jordan 1 high og dior'\n",
    "German = 'German Army Trainers'\n",
    "Chuck = 'Chuck 70 Classic Black 162058C'\n",
    "\n",
    "baseUrl = 'https://search.naver.com/search.naver?where=image&sm=tab_jum&query='\n",
    "searchTerm  = input ('검색어 입력: ')\n",
    "url = baseUrl + quote_plus(searchTerm)\n",
    "folder_path = 'C:/Users/msi/Desktop/openCV project/' + 신발이름\n",
    "\n",
    "#폴더 만들기\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/msi/Desktop/openCV project/chromedriver_win32/chromedriver.exe')\n",
    "driver.get(url)\n",
    "\n",
    "#스크롤 끝까지 내리기\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    time.sleep(0.5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "\n",
    "#이미지 url 찾기 밎 저장\n",
    "imgs = driver.find_elements_by_css_selector(\"img._img\")\n",
    "img_list = []\n",
    "for img in imgs:\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        img_list.append(img.get_attribute('src'))\n",
    "\n",
    "for num , link in enumerate(img_list):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    filetype = link[start:end]\n",
    "    urllib.request.urlretrieve(link, folder_path + '/'+ 신발이름 + ' ' + str(num+1)+ \".jpg\")\n",
    "\n",
    "print('완료')\n",
    "\n",
    "driver.close\n",
    "\n",
    "#'신발이름'이라고 표시되어 있는 부분에는 name의 신발을 각각 바꾸어가며 넣어주었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO모델로 학습시키기 전에 적절한 형태로 데이터를 가공하였습니다.<br>\n",
    "labelimg 툴(https://github.com/tzutalin/labelImg) 을 이용하여 선별한 사진들에서의 신발의 위치를 나타낸 txt파일을 얻었습니다.<br>\n",
    "![labelimg_result](report_photos/train_set(labelImg).png)<br>\n",
    "<img src=\"report_photos/labelImg_txt.png\" align=\"left\"> <br><br><br><br>\n",
    "txt 파일은 class, centerX, centerY, width, height 으로 구성되어 있습니다.<br>\n",
    "Google Drive의 Darknet 폴더의 custom에 이미지 데이터를 넣었놓았습니다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  학습데이터 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my_class.name 생성\n",
    "labelImg를 수행하여 함께 생성되었던 class.txt 파일(각 class의 name이 적혀있는 txt파일)을 my_class.name 파일로 수정하였습니다.<br>\n",
    "<img src=\"report_photos/my_classname.png\" align=\"left\"><br><br><br><br><br><br><br>\n",
    "#### my_yolo.cfg 생성\n",
    "darknet의 cfg 파일 중 yolov3.cfg의 복사본을 만들어 수정하였습니다.<br>\n",
    "\n",
    "[net] 에서는 한 번에 64개의 이미지를 읽어오도록 하고 최소 16개를 읽어올 수 있도록 의 batch를 64로 수정하고 subdivision은 16로 수정하였습니다.<br>\n",
    "max_batches 값은 class가 3개인 것을 가만하여 (calss) * 2000해서 6000개로 지정하였고, steps는 max_batches의 80%와 90%로 값인 4800, 5400으로 바꾸었습니다.<br>\n",
    "[yolo]에서 classes를 3으로 바꾸었습니다.<br>\n",
    "[yolo]위의 [convolutional]에서 filters 값은 (classes + coordinates + 1) * masks로 계산하여 (3+5)*3 = 24로 설정하였습니다.<br>\n",
    "\n",
    "#### my_text.txt, my_train.txt 생성\n",
    "각 .jpg 파일의 위치를 나타내는 txt파일을 생성하였습니다. 8대2의 비율로 shuffle을 활용하여 랜덤하게 train data와 test data로 나누었습니다.<br> Google Drive를 이용해서 COLAB을 사용할 계획이므로 Google Drive의 경로로 사진을 지정하였습니다.\n",
    "-결과<br>\n",
    "![labelimg_result](report_photos/train&test_txt.png)\n",
    "소스코드: train&test_txtfile.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "gdrive_path = '/content/gdrive/My Drive/darknet/custom/'\n",
    "image_path = 'C:/Users/msi/Desktop/openCV project/train'\n",
    "\n",
    "test_per = 0.2\n",
    "paths = []\n",
    "\n",
    "os.chdir(image_path)\n",
    "for a, b, files in os.walk('.'):\n",
    "    for i in files:\n",
    "        if i.endswith('.jpg'):\n",
    "            paths.append(gdrive_path + i + '\\n')\n",
    "            shuffle(paths)\n",
    "\n",
    "#path중 8:2로 train과 test로 나눔.\n",
    "paths_test = paths[:int(len(paths)*test_per)]\n",
    "path_train = paths[int(len(paths)*test_per):]\n",
    "\n",
    "with open('my_train.txt', 'w') as my_train_txt:\n",
    "    for path in path_train:\n",
    "        my_train_txt.write(path)\n",
    "\n",
    "with open('my_test.txt', 'w') as my_test_txt:\n",
    "    for path in paths_test:\n",
    "        my_test_txt.write(path)\n",
    "        \n",
    "#train이라는 폴더에 txt파일을 생성하고 확인한 뒤 직접 Google Drive의 darknet/custom 에다가 넣어주었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### my_obj.data 생성\n",
    "class = 3<br>\n",
    "train = /content/gdrive/My\\ Drive/darknet/custom/my_train.txt<br>\n",
    "valid = /content/gdrive/My\\ Drive/darknet/custom/my_test.txt<br>\n",
    "names = /content/gdrive/My\\ Drive/darknet/custom/my_classes.names<br>\n",
    "backup = backup<br>\n",
    "위와 같은 구성으로 my_obj.data 파일을 만들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLAB 개발환경 구축 및 데이터 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU를 사용하여 performance를 높이기 위해서 COLAB을 이용하여 프로젝트를 진행하였습니다.<br>\n",
    "개인 Google Drive에 YOLO로 학습을 하기위해 필요한 파일들을 구성해놓은 뒤 COLAB에 연결하였습니다.<br>\n",
    "COLAB에 darknet을 설치한 뒤 총 6000번의 학습을 진행하였습니다.<br>\n",
    "<img src=\"report_photos/5700...png\" align=\"left\"><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "5712번까지 학습하던 도중 학습이 멈춰 다음과 같이 5000번째 부터 다시 이어서 학습을 진행하였습니다.(6000번째에서 중단, 6000번째는 final로 저장)<br>\n",
    "![:(](report_photos/re5000.png)<br>\n",
    "결과:my_yolo_1000.weights,my_yolo_2000.weights,my_yolo_3000.weights,my_yolo_4000.weights,my_yolo_5000.weights,my_yolo_final.weights<br>\n",
    "(Google Drive의 darknet/backup 폴더에 복사하여 넣어두었습니다.)<br><br>\n",
    "Google Drive: https://drive.google.com/drive/folders/1bw7MUi8tJGqyEY5x9c0--_-b_uJD0lKe?usp=sharing<br>\n",
    "소스코드: openCV_training.ipynb<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 적합한 YOLO 학습 모델 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습하는 과정에서 오버피팅(Overfitting)이 발생했었을 수도 있기때문에 최적의 YOLO 학습 모델을 찾기 위해서 1000개 단위로 저장한 weights파일들의 mean average precision값을 구해보았습니다.<br>\n",
    "![fit_yolo](report_photos/1000.png)\n",
    "my_yolo_1000.weights의 경우 mean average precision가 89.07%\n",
    "![fit_yolo](report_photos/2000.png)\n",
    "my_yolo_2000.weights의 경우 mean average precision가 96.57%\n",
    "![fit_yolo](report_photos/3000.png)\n",
    "my_yolo_3000.weights의 경우 mean average precision가 95.36% \n",
    "![fit_yolo](report_photos/4000.png)\n",
    "my_yolo_4000.weights의 경우 mean average precision가 96.47%\n",
    "![fit_yolo](report_photos/5000.png)\n",
    "my_yolo_5000.weights의 경우 mean average precision가 95.59% \n",
    "![fit_yolo](report_photos/6000.png)\n",
    "my_yolo_6000.weights의 경우 mean average precision가 95.27% 라는 결과가 나왔습니다.<br>\n",
    "my_yolo_2000.weights가 96.57%로 가장 높은 mean average precision을 기록했고, 4000번 학습한 이후에는 오히려 mean average precision이 떨어지는 경향이 나타나 오버피팅이 되었다고 판단하였습니다.<br>\n",
    "따라서 가장 높은 mean average precision을 기록한 my_yolo_2000.weights 학습 모델을 이용하여 프로그램을 제작하기로 결정하였습니다.<br><br>\n",
    "소스코드: openCV_training.ipynb<br>\n",
    "COLAB 링크: https://colab.research.google.com/drive/1D0ePX-D2UpfAd58RZ8tR2DNYkL9ZybdN?usp=sharing<br>\n",
    "(데이터학습부분도 함께 포함되어 있으며 내용은 openCV_training.ipynb와 같습니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신발인식 GUI프로그램 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소스코드: shoes recognition program.ipynb"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from PIL import Image,ImageTk\n",
    "from tkinter import filedialog\n",
    "\n",
    "minimum_accuracy = 0.4\n",
    "width = 500\n",
    "image_file = \"C:/Users/msi/Desktop/openCV project/test_photos/Air jordan 1 high og dior 166.jpg\"\n",
    "title = \"shoes recognition program\"\n",
    "\n",
    "def ShoesDetection(image):\n",
    "    net = cv2.dnn.readNet('./my_weight/my_yolo_2000.weights','./custom/my_yolo.cfg')\n",
    "    classes = []\n",
    "    layers = []\n",
    "    scalesize = 0.00392 #1을 255로 나눈 값 반올림\n",
    "    minimum_accuracy = float(accuracySpin.get())\n",
    "    with open('./custom/my_classes.names', \"r\") as f:\n",
    "        for r in f.readlines():\n",
    "            classes.append(r.strip())\n",
    "    layerNames = net.getLayerNames()\n",
    "    for i in net.getUnconnectedOutLayers():\n",
    "        layers.append(layerNames[i[0] - 1])\n",
    "    h, w = image.shape[:2]\n",
    "    height = int(h * (width /w))\n",
    "    img = cv2.resize(image,(width, height))\n",
    "    blobImage = cv2.dnn.blobFromImage(img, scalesize, (416, 416), swapRB = True, crop = False)\n",
    "    net.setInput(blobImage)\n",
    "    outs = net.forward(layers)\n",
    "    locationbox = []\n",
    "    namebox = []\n",
    "    accuracy = []\n",
    "    \n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:] \n",
    "            class_id = np.argmax(scores) #scores에서 가장 높은 값을 해당 물체로 인식\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > minimum_accuracy:\n",
    "                #detection안의 값은 상대위치이므로 width와 height을 곱해줌.\n",
    "                centerX = int(detection[0] * width)\n",
    "                centerY = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                x = int(centerX - w/2)\n",
    "                y = int(centerY - h/2)\n",
    "                locationbox.append([x, y, w, h])\n",
    "                accuracy.append(float(confidence))\n",
    "                namebox.append(classes[class_id])\n",
    "    #노이즈 제거\n",
    "    indexes = cv2.dnn.NMSBoxes(locationbox, accuracy, minimum_accuracy, 0.4)\n",
    "    for i in range(len(locationbox)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = locationbox[i]\n",
    "            label = '{} {:,.2%}'.format(namebox[i], accuracy[i])\n",
    "            #신발마다 색깔 지정(에어 조던: 빨강, 척: 파랑, 독일군:초록)\n",
    "            if namebox[i] == 'Air jordan 1 high og dior':\n",
    "                color = (0,0,255)\n",
    "            elif namebox[i] == 'Chuck 70 Classic Black 162058C':\n",
    "                color = (255, 0, 0)\n",
    "            elif namebox[i] == 'German Army Trainers':\n",
    "                color = (0, 255, 0)\n",
    "            cv2.rectangle(img,(x,y),(x + w, y + h),color, 2)\n",
    "            #글씨가 위에 닿지 않도록하고 사각형 중간에 오도록\n",
    "            startY = y - 10 if y - 10 > 10 else y + 10\n",
    "            startX = int(x - w/2)\n",
    "            cv2.putText(img, label, (startX, startY), cv2.FONT_ITALIC, 0.5, (0,0,0), 2)\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    imgtk = ImageTk.PhotoImage(image=image)\n",
    "    detection_image.config(image=imgtk)\n",
    "    detection_image.image = imgtk\n",
    "\n",
    "def FileOpen():\n",
    "    file = filedialog.askopenfilename(initialdir = \"./\",title = \"Select file\",filetypes = ((\"jpeg files\",\"*.jpg\"),(\"all files\",\"*.*\")))\n",
    "    image_file = cv2.imread(file)\n",
    "    assert not isinstance(image_file,type(None))\n",
    "    ShoesDetection(image_file)\n",
    "    \n",
    "root = Tk()\n",
    "#root =Toplevel()#Tk() 자체에서 오류가 날 경우 root = Toplevel()로 실행시킨 뒤 다시 Tk()로 작동시키면 정상작동됩니다.\n",
    "root.title(title)\n",
    "root.geometry()\n",
    "\n",
    "read_image = cv2.imread(image_file)\n",
    "image = cv2.cvtColor(read_image, cv2.COLOR_BGR2RGB)\n",
    "image = Image.fromarray(image)\n",
    "imgtk = ImageTk.PhotoImage(image=image)\n",
    "\n",
    "label=Label(root, text=title)\n",
    "label.config(font=(\"Courier\", 15))\n",
    "label.grid(row=0,column=0,columnspan=4)\n",
    "\n",
    "accuracyLabel = Label(root, text = \"minimum accuracy: \")\n",
    "accuracyLabel.grid(row=1, column= 0)\n",
    "accuracyIntVar = IntVar(value = minimum_accuracy)\n",
    "accuracySpin = Spinbox(root, textvariable = accuracyIntVar, from_= 0, to = 1, increment = 0.05, justify = RIGHT)\n",
    "accuracySpin.grid(row=1, column = 1)\n",
    "\n",
    "Button(root,text=\"File Select\", height=2,command=lambda:FileOpen()).grid(row=1, column=2, columnspan=2, sticky=(W, E))\n",
    "\n",
    "detection_image=Label(root, image = imgtk)\n",
    "detection_image.grid(row=2,column=0,columnspan=3)\n",
    "\n",
    "ShoesDetection(read_image)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 결과\n",
    "![result](report_photos/result.png)\n",
    "![result](report_photos/result1.png)\n",
    "위 사진에서 보듯이 신발인식과 정확도 변경 및 사진 변경이 원활하게 되었습니다.<br>\n",
    "(테스트에 사용한 사진들은 학습에 사용하지 않은 사진들이며, 프로그램 수요자의 취지에 맞추기 위해 신발만 나타나있는 사진이 아니라 전신이나 하반신까지 나오는 사진을 선택하였습니다.)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한계점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 신발 자체를 훈련시킨 사진들과 다르게 사진 속 신발의 사이즈가 작아서 그런지 인식률이 많이 떨어졌습니다.<br>\n",
    "![fit_yolo](report_photos/threshold_point.png)\n",
    "<br>\n",
    "2. 크롤링하여 얻은 신발 사진 대부분이 신발 두 쪽을 한 번에 학습시키기에 적절하지 않은 이미지여서 신발 한 쪽씩 훈련시켰더니 각 신발마다 인식률이 달랐고, 신발이 가까우 붙어있는 경우 글씨가 붙어서 잘 알아보기 힘든 경우가 발생하였습니다.<br>\n",
    "![fit_yolo](report_photos/threshold_point3.png)\n",
    "<br>\n",
    "3. 크롤링을 통해 얻은 사진들이 중복되는 경우가 많아서 이로 인해 정확도가 떨어졌을 가능성이 있습니다.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 주요 참고자료만 남겼습니다. 추가적으로 구글링을 주로 활용하였습니다.\n",
    "- github, AlexeyAB/darknet https://github.com/AlexeyAB/darknet#how-to-train-to-detect-your-custom-objects\n",
    "- Stack Overflow, https://stackoverflow.com/\n",
    "- 파이썬 표준 라이브러리, \"tkinter — Tcl/Tk 파이썬 인터페이스\", https://docs.python.org/ko/3/library/tkinter.html\n",
    "- pyimagesearch,\"Object detection with deep learning and OpenCV\",https://www.pyimagesearch.com/2017/09/11/object-detection-with-deep-learning-and-opencv/\n",
    "- 크리애플, https://www.creapple.com/home/main\n",
    "- 어쩐지 오늘은, \"openCV - 이미지/ 비디오 읽기\", https://zzsza.github.io/data/2018/01/23/opencv-1/\n",
    "- 봉식이와 캔따개, \"Python으로 OpenCV를 사용하여 YOLO Object detection\", https://bong-sik.tistory.com/16\n",
    "- Enough is not enough, \"[Object Detection] darknet custom 학습하기\", https://eehoeskrap.tistory.com/370 [Enough is not enough]\n",
    "- Yun Dae Hee, \"Python tkinter 강좌\", https://076923.github.io/posts/Python-tkinter-32/\n",
    "- 오세원 블로그, \"Theft Chaser : Yolo를 활용한 도둑탐지 - Labeling, Yolo 학습\", https://osw51.tistory.com/6\n",
    "- J_Remind, \"(YOLO) 이미지 학습\", https://j-remind.tistory.com/64\n",
    "- DSC Ewha ,\"Image labeling 및 Yolo darkflow/darknet관련 프로젝트 분석\",https://dsc-ewha.tistory.com/51\n",
    "- catharsis, \"[YOLO - darkflow] YOLO와 Python을 이용한 object detection (2) - image detection\" ,https://reyrei.tistory.com/17"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
